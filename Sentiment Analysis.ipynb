{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c0db900",
   "metadata": {},
   "source": [
    "## Install and Import Dependicies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86416637",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu113\n",
      "Collecting torch\n",
      "  Downloading https://download.pytorch.org/whl/cu113/torch-1.12.1%2Bcu113-cp39-cp39-win_amd64.whl (2143.3 MB)\n",
      "     ---------------------------------------- 2.1/2.1 GB 932.0 kB/s eta 0:00:00\n",
      "Collecting torchvision\n",
      "  Downloading https://download.pytorch.org/whl/cu113/torchvision-0.13.1%2Bcu113-cp39-cp39-win_amd64.whl (4.7 MB)\n",
      "     ---------------------------------------- 4.7/4.7 MB 3.2 MB/s eta 0:00:00\n",
      "Collecting torchaudio\n",
      "  Downloading https://download.pytorch.org/whl/cu113/torchaudio-0.12.1%2Bcu113-cp39-cp39-win_amd64.whl (1.2 MB)\n",
      "     ---------------------------------------- 1.2/1.2 MB 3.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\suley\\anaconda3\\lib\\site-packages (from torch) (4.1.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\suley\\anaconda3\\lib\\site-packages (from torchvision) (1.21.5)\n",
      "Requirement already satisfied: requests in c:\\users\\suley\\anaconda3\\lib\\site-packages (from torchvision) (2.26.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\suley\\anaconda3\\lib\\site-packages (from torchvision) (9.0.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\suley\\anaconda3\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\suley\\anaconda3\\lib\\site-packages (from requests->torchvision) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\suley\\anaconda3\\lib\\site-packages (from requests->torchvision) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\suley\\anaconda3\\lib\\site-packages (from requests->torchvision) (2021.10.8)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "Successfully installed torch-1.12.1+cu113 torchaudio-0.12.1+cu113 torchvision-0.13.1+cu113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='pypi.org', port=443): Read timed out. (read timeout=15)\")': /simple/torchvision/\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14c6c5c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.22.2-py3-none-any.whl (4.9 MB)\n",
      "Requirement already satisfied: requests in c:\\users\\suley\\anaconda3\\lib\\site-packages (2.26.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\suley\\anaconda3\\lib\\site-packages (4.11.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\suley\\anaconda3\\lib\\site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\suley\\anaconda3\\lib\\site-packages (from transformers) (2022.3.15)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\suley\\anaconda3\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\suley\\anaconda3\\lib\\site-packages (from transformers) (1.21.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\suley\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\suley\\anaconda3\\lib\\site-packages (from transformers) (4.64.0)\n",
      "Collecting huggingface-hub<1.0,>=0.9.0\n",
      "  Downloading huggingface_hub-0.10.0-py3-none-any.whl (163 kB)\n",
      "     -------------------------------------- 163.5/163.5 kB 1.6 MB/s eta 0:00:00\n",
      "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
      "  Downloading tokenizers-0.12.1-cp39-cp39-win_amd64.whl (3.3 MB)\n",
      "     ---------------------------------------- 3.3/3.3 MB 3.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\suley\\anaconda3\\lib\\site-packages (from requests) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\suley\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\suley\\anaconda3\\lib\\site-packages (from requests) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\suley\\anaconda3\\lib\\site-packages (from requests) (2021.10.8)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\suley\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\suley\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.9.0->transformers) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\suley\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\suley\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
      "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.10.0 tokenizers-0.12.1 transformers-4.22.2\n"
     ]
    }
   ],
   "source": [
    "! pip install transformers requests beautifulsoup4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf0a6199",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0efa9e",
   "metadata": {},
   "source": [
    "## Instantiate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ea5f9cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1e0319ae2fc406abd90b3e8eb6b6078",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/39.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suley\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:123: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\suley\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a33007242da4cd9a629a28b201f280a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/953 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbd013bfa995437e9c94a5d2d3ec2079",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/872k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aee7938b51d4741915c8fb42fd520b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4520ef50d8a347f4bf8dd1dddf1c5768",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/669M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"nlptown/bert-base-multilingual-uncased-sentiment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0d7ec4",
   "metadata": {},
   "source": [
    "## Encode and Calculate Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bce9625",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.encode(\"I hated this, absolutely the worst\", return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "221d61fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,   151, 39487, 10163, 10372,   117, 35925, 10563, 10103, 43060,\n",
       "           102]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44b47df5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] i hated this, absolutely the worst [SEP]'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27c54451",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d8f86a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[ 4.8750,  1.7880, -0.8356, -3.0027, -2.0727]],\n",
       "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "376b92a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.8750,  1.7880, -0.8356, -3.0027, -2.0727]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc6bbe34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(torch.argmax(result.logits) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ef73294",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.encode(\"This is amazing, I loved it. GREAT!\", return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8da942a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0158beb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(torch.argmax(result.logits) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f56ee782",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.encode(\"It was okay!\", return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b4d1a432",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2371c34a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(torch.argmax(result.logits) + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec159ce",
   "metadata": {},
   "source": [
    "## Collect Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "16ed209e",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(\"https://www.yelp.com/biz/nusr-et-steakhouse-istanbul-9\")\n",
    "soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "regex = re.compile(\".*comment.*\")\n",
    "results = soup.find_all(\"p\", {\"class\":regex})\n",
    "reviews = [result.text for result in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a1d7c653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"O my god it's the best. I hated the one in dubai, it was too expensive and the service was awful, this covered my last experience completely. The service was amazing in Istanbul and the food quality was above expectation. I only wish they improve their dubai quality and service to this standard.\""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008a6a1e",
   "metadata": {},
   "source": [
    "## Load Reviews into DataFrame and Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "076fee5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "29f04644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O my god it's the best. I hated the one in dub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Writing this review for the service. The food ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It's extremely touristy and super overrated. T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It's good. Fantastic. However, I think it is o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amazing steak! service also good quality but p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review\n",
       "0  O my god it's the best. I hated the one in dub...\n",
       "1  Writing this review for the service. The food ...\n",
       "2  It's extremely touristy and super overrated. T...\n",
       "3  It's good. Fantastic. However, I think it is o...\n",
       "4  Amazing steak! service also good quality but p..."
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(np.array(reviews), columns = [\"review\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e45b1219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"O my god it's the best. I hated the one in dubai, it was too expensive and the service was awful, this covered my last experience completely. The service was amazing in Istanbul and the food quality was above expectation. I only wish they improve their dubai quality and service to this standard.\""
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0, \"review\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8dcf37d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_score(review):\n",
    "    tokens = tokenizer.encode(review, return_tensors=\"pt\")\n",
    "    result = model(tokens)\n",
    "    return int(torch.argmax(result.logits) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ce451eac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_score(df.loc[0, \"review\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e6ab57ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O my god it's the best. I hated the one in dub...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Writing this review for the service. The food ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It's extremely touristy and super overrated. T...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It's good. Fantastic. However, I think it is o...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amazing steak! service also good quality but p...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Great food overpriced and little overrated We ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I may be one of very few who have this opinion...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>THE BEST STEAK HOUSE SERVICE !! If you're in T...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>This is the original restaurant of the Instagr...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Not sure why this place doesn't have a better ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  O my god it's the best. I hated the one in dub...          5\n",
       "1  Writing this review for the service. The food ...          2\n",
       "2  It's extremely touristy and super overrated. T...          2\n",
       "3  It's good. Fantastic. However, I think it is o...          4\n",
       "4  Amazing steak! service also good quality but p...          5\n",
       "5  Great food overpriced and little overrated We ...          3\n",
       "6  I may be one of very few who have this opinion...          3\n",
       "7  THE BEST STEAK HOUSE SERVICE !! If you're in T...          5\n",
       "8  This is the original restaurant of the Instagr...          4\n",
       "9  Not sure why this place doesn't have a better ...          3"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"sentiment\"] = df[\"review\"].apply(lambda x: sentiment_score(x[:512]))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b8d1723f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It\\'s extremely touristy and super overrated. The lines are long people dress up and it\\'s like the equivalent of going to outback steakhouse in America. I understand the gimmick with the whole salt Bae thing.. Bey..?It worked. The place is always crowded with tourists. They make great fries and a pretty good burger but you\\'ll find the same for half the price at any burger place place within the 10 mile radius of the restaurant.You cannot order lamb unless you\\'re there with family because the portions are huge. Five people. It\\'s sort of a \" thing to do\" like visit \\xa0katz deli when you\\'re in New York.*Do not order the steak salad because it is sliced deli meat on top of arugula..For $30 USDThat\\'s almost 250 Turkish lira.For a few slices of processed meat'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[2, \"review\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bf82b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
